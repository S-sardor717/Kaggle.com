{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10010384,"sourceType":"datasetVersion","datasetId":6145991}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install cloudscraper","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:08:33.120821Z","iopub.execute_input":"2024-11-23T18:08:33.121286Z","iopub.status.idle":"2024-11-23T18:08:43.200659Z","shell.execute_reply.started":"2024-11-23T18:08:33.121233Z","shell.execute_reply":"2024-11-23T18:08:43.198934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport re\nimport pandas as pd\nimport cloudscraper\nfrom collections import defaultdict\nfrom datetime import date\nfrom geopy.geocoders import Nominatim\nfrom geopy.exc import GeocoderTimedOut","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:08:43.207431Z","iopub.execute_input":"2024-11-23T18:08:43.207778Z","iopub.status.idle":"2024-11-23T18:08:43.87713Z","shell.execute_reply.started":"2024-11-23T18:08:43.207734Z","shell.execute_reply":"2024-11-23T18:08:43.876044Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![](https://s2.glbimg.com/FvxyE6pbsWUIG8kOnd-ceX_db8w=/620x430/e.glbimg.com/og/ed/f/original/2017/08/30/saopaulo.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Main code do wabscrap and generate Sao Paulo Apartments price","metadata":{}},{"cell_type":"markdown","source":"**Notes about this code**\n\nThere are still some changes I need to make. The first one is a bug that sometimes occurs with the ParkingSpaces, which is related to not recognizing some values. Because of this, we can't create a DataFrame and upload the dataset. I manually fixed it the first time (It was just 2 values that weren't recognized so it didn't took too much time, it hardly happens), but I intend to add a function to verify each iteration, checking the array size to ensure all variables are filled. This will help prevent bugs in the future.\n\nFurthermore, I'll set up the code to run every month to generate the dataset. Since I'm a real estate enthusiast and have plans to live in São Paulo someday, this will be a valuable tool.\n\nOther upgrades include adding features such as CEP (a postal code that identifies the address location), neighborhood quality, and more.","metadata":{}},{"cell_type":"code","source":"scraper = cloudscraper.create_scraper(\n    browser={\n        \"browser\": \"chrome\",\n        \"platform\": \"windows\",\n        \"desktop\": True,\n    }\n)\n\nprice_r = r'\"mainValue\"\\s*[:]\\s*(\\d+)\\s*'\nempty_r = r'\"emptyValue\":(true|false)'\nid_r = r'\"id\":\"\\s*(\\d+)\"'\narea_r = r'\"usableAreas\":\"([\\d\\s\\-]+)\"'\nbedrooms_r = r'\"bedrooms\":\"([\\d\\s\\-]+)\"'\nbathrooms_r = r'\"bathrooms\":\"([\\d\\s\\-]+)\"'\nparkingSpaces_r = r'\"parkingSpaces\":\"([\\d\\s\\-]+)\"'\ncreated_date_r = r'\"createdDate\":\"([\\d\\-T:Z]+)\"'\naddress_r = r'\"(city|streetNumber|stateAcronym|street|neighborhood)\":\"([^\"]+)\"'\nbelow_price_r = r'\"belowPrice\":(true|false)'\n\ndata = {}\n\nprices = []\nids = []\nareas = []\nbedrooms = []\nbathrooms = []\nparkingSpaces = []\ncreated_dates = []\naddresses = []\nbelow_prices = []\nprices = []\nbelow_prices = []\nloc = []\n\n# Maximium of 100 pages\nfor pag in range(1, 2): ## The maximum value here is 101, I used 101 to generate the database\n    for rooms in range(1, 3): ## Maximum value is 5\n        for baths in range(1, 3): ## Maximum value is 5\n            for garage in range(1, 3): ## Maximum value is 5\n                url = f\"https://www.zapimoveis.com.br/venda/apartamentos/sp+sao-paulo/?__ab=sup-hl-pl:newC,exp-aa-test:control,super-high:new,off-no-hl:new,pos-zap:new,zapproppos:new,nlb-ldp:control,ltroffline:control&transacao=venda&tipos=apartamento_residencial&pagina={pag}&banheiros={baths}&quartos={rooms}&vagas={garage}\"\n\n                search_text = 'Não encontramos resultados para a busca'\n                r = scraper.get(url)\n\n                if search_text in r.text:\n                    last_page = True\n                else:\n                    last_page = False\n\n                if r.status_code == 200 and last_page is False:\n                    page = BeautifulSoup(r.text, 'html5lib')\n\n                    # Inicialização\n                    bloco = defaultdict(lambda: '') \n                    loc = []\n\n                    results = re.findall(address_r, page.text)\n                    results = [t for t in results if t != ('city', 'sao-paulo')]\n\n                    for chave, valor in results:\n                        bloco[chave] = valor\n                        \n                        if {'city', 'stateAcronym', 'neighborhood'}.issubset(bloco.keys()):\n                            # Formatting address\n                            city = bloco['city']\n                            stateAcronym = bloco['stateAcronym']\n                            street = bloco['street']\n                            streetNumber = bloco['streetNumber']\n                            neighborhood = bloco['neighborhood']\n\n                            full_address = f\"{street} {streetNumber}, {neighborhood} - {city}/{stateAcronym}\".strip(\", \")\n                            loc.append(full_address)\n\n                            bloco.clear()\n\n                    prices_raw = re.findall(price_r, page.text)\n                    below_prices_raw = re.findall(below_price_r, page.text)\n                    empty_values = re.findall(empty_r, page.text)\n\n                    i = 0\n                    for j in range(len(empty_values)):\n                        if i < len(prices_raw):\n                            if empty_values[j] == 'true':\n                                prices.append(0)\n                                below_prices.append('false')\n                            else:\n                                prices.append(prices_raw[i])\n                                below_prices.append(below_prices_raw[i])\n                            i += 1\n                        else:\n                            prices.append(0)\n                            below_prices.append('false')\n\n                    ids += re.findall(id_r, page.text)\n                    areas += re.findall(area_r, page.text)\n                    bedrooms += re.findall(bedrooms_r, page.text)\n                    bathrooms += re.findall(bathrooms_r, page.text)\n                    parkingSpaces += re.findall(parkingSpaces_r, page.text)\n                    created_dates += re.findall(created_date_r, page.text)\n                    addresses += loc\n\n                    data = {\n                        'ID': ids,\n                        'created_date': created_dates,\n                        'Price': prices,\n                        'below_price': below_prices,\n                        'Area': areas,\n                        'Adress': addresses,\n                        'Bedrooms': bedrooms,\n                        'Bathrooms': bathrooms,\n                        'Parking_Spaces': parkingSpaces,\n                    }\n\ndf = pd.DataFrame(data)\n\ntoday = date.today()\ntoday.strftime('%Y-%m-%d')\n\ndf['extract_date'] = today\n\n## Getting Latidude and longitude\ngeolocator = Nominatim(user_agent=\"my_geocoder\")\n\ndef geocode_address(address):\n    try:\n        location = geolocator.geocode(address, addressdetails=True, timeout=10)\n        if location:\n            latitude = location.latitude\n            longitude = location.longitude\n            return pd.Series([latitude, longitude])\n        else:\n            return pd.Series([None, None])\n    except GeocoderTimedOut:\n        return pd.Series([None, None])\n\ndf[[\"Latitude\", \"Longitude\"]] = df[\"Adress\"].apply(geocode_address)\n\n# df.to_csv('file.csv', index=False)\n\n## How to treat to remove rows from apartments on pre-sale or in construction\n## If you want to check opportunities to buy before the appartments are built you shouldn't run the lines below\n\ndf = df[~df[['Area', 'Bedrooms', 'Bathrooms', 'Parking_Spaces']].apply(lambda x: x.str.contains('-', regex=False)).any(axis=1)]\n\ndf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:08:43.878665Z","iopub.execute_input":"2024-11-23T18:08:43.879234Z","iopub.status.idle":"2024-11-23T18:10:10.502163Z","shell.execute_reply.started":"2024-11-23T18:08:43.879193Z","shell.execute_reply":"2024-11-23T18:10:10.501033Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Thanks for reading until here! Hope this code helps and if you have some time, feel free to add feedbacks os ideas!","metadata":{}},{"cell_type":"markdown","source":"If you have any questions, feel free to ask me!","metadata":{}}]}